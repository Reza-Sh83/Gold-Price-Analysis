{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NydDd_N1DgA7"
      },
      "source": [
        "# ðŸ“Š **Econophysics: Gold Price Analysis**\n",
        "This notebook presents an analysis of gold price data using Econophysics techniques. The workflow includes:\n",
        "- Calculating price differences and normalized differences\n",
        "- Plotting probability density functions (PDF) using Freedman-Diaconis bins and Gaussian KDE\n",
        "- Analyzing ordinal patterns and calculating permutation entropy\n",
        "- Visualizing conditional probabilities with a transition matrix heatmap\n",
        "\n",
        "ðŸ”¥ **Key Steps**:\n",
        "- Reading the gold price data\n",
        "- Computing and plotting normalized differences\n",
        "- Ordinal pattern and entropy analysis\n",
        "- Heatmap visualization of transition matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW5tPPxrDgBJ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.optimize import curve_fit\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import math\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Read the file\n",
        "def read_file(file_path):\n",
        "    \"\"\"\n",
        "    Load the gold price data from the file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file containing gold price data.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: An array of prices.\n",
        "    \"\"\"\n",
        "    prices = np.loadtxt(file_path)\n",
        "    return prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj3G9Yf4DgBN"
      },
      "outputs": [],
      "source": [
        "def preprocess_gold_data(prices, window_size=10):\n",
        "    \"\"\"\n",
        "    Preprocesses Gold price data to remove microstructure noise.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path: str, path to the Gold price data file.\n",
        "    - window_size: int, size of the moving average window.\n",
        "\n",
        "    Returns:\n",
        "    - x0: numpy.ndarray, standardized differences of the moving average.\n",
        "    - tau: list, range of lag values for analysis.\n",
        "    - M1_a: numpy.ndarray, measure 1 computed from kernel density estimation.\n",
        "    - M2_a: numpy.ndarray, measure 2 computed from kernel density estimation.\n",
        "    \"\"\"\n",
        "    # Step 2: Compute the moving average using convolution\n",
        "    moving_avg = np.convolve(prices, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "    # Replace NA values at the start with the first non-NA value (if any)\n",
        "    moving_avg = np.concatenate(([prices[0]], moving_avg))\n",
        "\n",
        "    # Calculate the difference of the moving average\n",
        "    diff = np.diff(moving_avg)\n",
        "\n",
        "    # Standardizing the data\n",
        "    x0 = (diff - np.nanmean(diff)) / np.nanstd(diff)\n",
        "\n",
        "    # Remove non-finite values\n",
        "    x0 = x0[np.isfinite(x0)]\n",
        "\n",
        "    # Parameters for kernel density estimation\n",
        "    bw = 0.2\n",
        "    na = 6\n",
        "    tau = np.arange(1, 11)  # Range of tau from 1 to 10\n",
        "    avec = np.linspace(np.min(x0), np.max(x0), na)\n",
        "\n",
        "    # Scaling factor for kernel density estimation\n",
        "    SF = 1 / (bw * np.sqrt(2 * np.pi))\n",
        "\n",
        "    # Initialize result vectors for M1 and M2\n",
        "    M1_a = np.zeros(len(tau))\n",
        "    M2_a = np.zeros(len(tau))\n",
        "\n",
        "    # Loop over tau to compute M1 and M2\n",
        "    for i in range(len(tau)):\n",
        "        # Calculate differences and their squares with lag tau[i]\n",
        "        dx = np.diff(x0, n=tau[i])\n",
        "        dx2 = dx ** 2\n",
        "        nx = len(dx)\n",
        "\n",
        "        # Initialize kernel matrix\n",
        "        Kmat = np.zeros((na, nx))\n",
        "\n",
        "        # Fill the kernel matrix for each j\n",
        "        for j in range(nx):\n",
        "            Kmat[:, j] = SF * np.exp(-0.5 * ((x0[j] - avec) ** 2) / (bw ** 2))\n",
        "\n",
        "        # Sum of weights for the last row (kernel sum for na-th point)\n",
        "        Ksum = np.sum(Kmat[na - 1, :])\n",
        "\n",
        "        # Compute M1 and M2 using the kernel sum\n",
        "        if Ksum != 0:\n",
        "            M1_a[i] = np.sum(Kmat[na - 1, :] * dx) / Ksum\n",
        "            M2_a[i] = np.sum(Kmat[na - 1, :] * dx2) / Ksum\n",
        "        else:\n",
        "            M1_a[i] = np.nan\n",
        "            M2_a[i] = np.nan\n",
        "\n",
        "    # Replace any remaining non-finite values in M1_a and M2_a\n",
        "    M1_a[np.isnan(M1_a)] = 0\n",
        "    M2_a[np.isnan(M2_a)] = 0\n",
        "    # Plotting the results and save to a PDF file\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(tau, M1_a / tau, 'b-', label=r'M$^{(1)}(0, \\tau)$ / $\\tau$')\n",
        "    plt.scatter(tau, M1_a / tau, color='red')\n",
        "    plt.xlabel(r'$\\tau$')\n",
        "    plt.ylabel(r'M$^{(1)}(0, \\tau)$ / $\\tau$')\n",
        "    plt.ylim([np.min(M1_a / tau), np.max(np.abs(M1_a / tau))])\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(tau, M2_a / tau, 'b-', label=r'M$^{(2)}(0, \\tau)$ / $\\tau$')\n",
        "    plt.scatter(tau, M2_a / tau, color='red')\n",
        "    plt.xlabel(r'$\\tau$')\n",
        "    plt.ylabel(r'M$^{(2)}(0, \\tau)$ / $\\tau$')\n",
        "    plt.ylim([0, np.max(M2_a / tau)])\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return np.array([np.mean(prices[i:i + window_size]) for i in range(len(prices) - window_size + 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnao5l_ODgBQ"
      },
      "outputs": [],
      "source": [
        "# Step 2: Calculate normalized price differences\n",
        "def calculate_normalized_price_diff(prices):\n",
        "    \"\"\"\n",
        "    Calculate the normalized price difference.\n",
        "\n",
        "    Args:\n",
        "        prices (np.ndarray): Array of price values.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Price differences.\n",
        "        np.ndarray: Normalized price differences.\n",
        "    \"\"\"\n",
        "    # Calculate price difference (x)\n",
        "    price_diff = np.diff(prices)\n",
        "\n",
        "    # Standard deviation of price differences\n",
        "    sd_price_diff = np.std(price_diff)\n",
        "\n",
        "    # Normalize the differences (y = x/sd(x))\n",
        "    normalized_diff = price_diff / sd_price_diff\n",
        "\n",
        "    return price_diff, normalized_diff\n",
        "# Plot normalized difference y(N)\n",
        "def plot_y_N(normalized_diff):\n",
        "    \"\"\"\n",
        "    Plot the normalized differences y(N).\n",
        "\n",
        "    Args:\n",
        "        normalized_diff (np.ndarray): Normalized price differences.\n",
        "    \"\"\"\n",
        "    plt.plot(np.arange(len(normalized_diff)), normalized_diff, label='Normalized y(N)', color='blue')\n",
        "    plt.title('Normalized Difference y(N)')\n",
        "    plt.xlabel('N (Index)')\n",
        "    plt.ylabel('y(N)')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF2f88EfDgBS"
      },
      "outputs": [],
      "source": [
        "# Step 4: Calculate PDF with Freedman-Diaconis Rule\n",
        "def calculate_freedman_diaconis_bins(normalized_diff):\n",
        "    \"\"\"\n",
        "    Calculate the number of bins using Freedman-Diaconis Rule.\n",
        "\n",
        "    Args:\n",
        "        normalized_diff (np.ndarray): Normalized price differences.\n",
        "\n",
        "    Returns:\n",
        "        int: Number of bins.\n",
        "    \"\"\"\n",
        "    q1 = np.percentile(normalized_diff, 25)\n",
        "    q3 = np.percentile(normalized_diff, 75)\n",
        "    iqr = q3 - q1\n",
        "\n",
        "    bin_width = 2 * iqr * len(normalized_diff) ** (-1/3)\n",
        "    num_bins = int(np.ceil((normalized_diff.max() - normalized_diff.min()) / bin_width))\n",
        "\n",
        "    return num_bins\n",
        "\n",
        "def calculate_pdf_with_freedman_diaconis(normalized_diff, a = 1, b = 3.9):\n",
        "    \"\"\"\n",
        "    Calculate and plot the PDF using the Freedman-Diaconis rule.\n",
        "\n",
        "    Args:\n",
        "        normalized_diff (np.ndarray): Normalized price differences.\n",
        "        a (float): Parameter a for the fit function.\n",
        "        b (float): Parameter b for the fit function.\n",
        "    \"\"\"\n",
        "    num_bins = calculate_freedman_diaconis_bins(normalized_diff)\n",
        "    hist, bin_edges = np.histogram(normalized_diff, bins=num_bins, density=True)\n",
        "\n",
        "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "\n",
        "    # Filter out non-positive bin centers\n",
        "    valid_indices = bin_centers > 0\n",
        "    bin_centers_filtered = bin_centers[valid_indices]\n",
        "    hist_filtered = hist[valid_indices]\n",
        "\n",
        "    # Define the manual fit function\n",
        "    def fit_function(y):\n",
        "        return a * (1 / (y ** b))\n",
        "\n",
        "    # Generate fitted data for the range from 1 to 4\n",
        "    y_fit = np.linspace(1,20, 1000)\n",
        "    fitted_values = fit_function(y_fit)\n",
        "\n",
        "    # Plotting\n",
        "    plt.plot(bin_centers, hist, label=f'PDF with {num_bins} bins (Freedman-Diaconis)', color='green')\n",
        "    plt.plot(y_fit, fitted_values, label=f'Fitted function: (1/y^{b:.2f})', color='red')\n",
        "\n",
        "    # Add text annotation for the fit function\n",
        "    plt.text(1.5, max(fitted_values)*0.8, f'Fit: (1/y^{b:.2f})', fontsize=12, color='red')\n",
        "\n",
        "    plt.xscale('log')\n",
        "    plt.yscale('log')\n",
        "    plt.title('Probability Density Function (PDF) - Log-Log Scale')\n",
        "    plt.xlabel('Data (log scale)')\n",
        "    plt.ylabel('Probability Density (log scale)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BpdR9SdDgBT"
      },
      "outputs": [],
      "source": [
        "# Step 5: Calculate Ordinal Patterns and Permutation Entropy\n",
        "def ordinal_pattern(prices, D):\n",
        "    \"\"\"\n",
        "    Calculate ordinal patterns for the time series.\n",
        "\n",
        "    Args:\n",
        "        prices (np.ndarray): Time series data.\n",
        "        D (int): Embedding dimension.\n",
        "\n",
        "    Returns:\n",
        "        list: Valid ordinal patterns.\n",
        "        dict: Frequency of each ordinal pattern.\n",
        "    \"\"\"\n",
        "    n = len(prices)\n",
        "    if D > n:\n",
        "        raise ValueError(\"Embedding dimension D must be smaller than the length of the time series.\")\n",
        "\n",
        "    windows = np.lib.stride_tricks.sliding_window_view(prices, D)\n",
        "\n",
        "    valid_patterns = []\n",
        "    for window in windows:\n",
        "        if len(set(window)) != D:\n",
        "            continue\n",
        "        sorted_indices = np.argsort(window)\n",
        "        valid_patterns.append(tuple(sorted_indices))\n",
        "\n",
        "    pattern_counts = Counter(valid_patterns)\n",
        "    return valid_patterns, pattern_counts\n",
        "# Permutation Entropy calculation\n",
        "def calculate_permutation_entropy(pattern_counts, D):\n",
        "    total_patterns = sum(pattern_counts.values())\n",
        "    if total_patterns == 0:\n",
        "        return 0\n",
        "\n",
        "    probabilities = np.array([count / total_patterns for count in pattern_counts.values()])\n",
        "    entropy = -np.sum(probabilities * np.log(probabilities))\n",
        "    max_entropy = np.log(math.factorial(D))\n",
        "\n",
        "    return entropy / max_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOIpVllZDgBa"
      },
      "outputs": [],
      "source": [
        "# Step 6: Calculate conditional probabilities and transition matrix\n",
        "def calculate_conditional_probabilities_and_matrix(valid_patterns, D):\n",
        "    \"\"\"\n",
        "    Calculates the conditional probabilities and transition matrix.\n",
        "\n",
        "    Args:\n",
        "        valid_patterns (list): List of valid ordinal patterns.\n",
        "        D (int): Embedding dimension.\n",
        "\n",
        "    Returns:\n",
        "        tuple: conditional_probabilities (dict), transition_matrix (ndarray), unique_patterns (list)\n",
        "    \"\"\"\n",
        "    num_patterns = math.factorial(D)\n",
        "    data = {'Current': valid_patterns[:-1], 'Next': valid_patterns[1:]}\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    unique_patterns = sorted(set(valid_patterns), key=lambda p: tuple(p))\n",
        "    pattern_to_idx = {pattern: idx for idx, pattern in enumerate(unique_patterns)}\n",
        "\n",
        "    transition_matrix = np.zeros((num_patterns, num_patterns))\n",
        "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        current_pattern = row['Current']\n",
        "        next_pattern = row['Next']\n",
        "        transition_counts[current_pattern][next_pattern] += 1\n",
        "        current_idx = pattern_to_idx[current_pattern]\n",
        "        next_idx = pattern_to_idx[next_pattern]\n",
        "        transition_matrix[current_idx][next_idx] += 1\n",
        "\n",
        "    row_sums = transition_matrix.sum(axis=1, keepdims=True)\n",
        "    transition_matrix = np.divide(transition_matrix, row_sums, where=row_sums != 0)\n",
        "\n",
        "    conditional_probabilities = {current: {next_: count / sum(next_patterns.values())\n",
        "                                           for next_, count in next_patterns.items()}\n",
        "                                 for current, next_patterns in transition_counts.items()}\n",
        "\n",
        "    return conditional_probabilities, transition_matrix, unique_patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8PX-7QyDgBb"
      },
      "outputs": [],
      "source": [
        "# Step 7: Plot the transition matrix heatmap with red-blue colors\n",
        "def plot_transition_matrix_heatmap(transition_matrix, unique_patterns, D):\n",
        "    \"\"\"\n",
        "    Plots a heatmap of the transition matrix with a red-blue color scheme,\n",
        "    adjusting figure size and font size dynamically based on D.\n",
        "\n",
        "    Args:\n",
        "        transition_matrix (np.ndarray): Transition matrix.\n",
        "        unique_patterns (list): List of unique ordinal patterns.\n",
        "    \"\"\"\n",
        "    # Plot the heatmap with custom colors and annotations\n",
        "    plt.imshow(transition_matrix, cmap='Blues', vmin=0, vmax=1)  \n",
        "\n",
        "    # Add colorbar \n",
        "    plt.colorbar() \n",
        "\n",
        "    # Set axis labels and title with dynamic font size\n",
        "    plt.xlabel('Next Pattern')\n",
        "    plt.ylabel('Current Pattern')\n",
        "    plt.title(f'Transition Matrix Heatmap for D={D}')\n",
        "\n",
        "\n",
        "    # Disable tick marks and labels\n",
        "    plt.xticks([], [])\n",
        "    plt.yticks([], [])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'Transition Matrix Heatmap for D={D}', dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yLwWmnUrDgBc",
        "outputId": "8c4c9feb-db5f-488c-ce0f-65dc042de746"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "file_path = r\"YOUR FILE PATH\"\n",
        "prices = read_file(file_path)\n",
        "prices = preprocess_gold_data(prices, window_size=17)\n",
        "\n",
        "price_diff, normalized_diff = calculate_normalized_price_diff(prices)\n",
        "plot_y_N(normalized_diff)\n",
        "\n",
        "calculate_pdf_with_freedman_diaconis(normalized_diff)\n",
        "for D in range(2,8):\n",
        "    valid_patterns, pattern_counts = ordinal_pattern(prices, D)\n",
        "\n",
        "    entropy = calculate_permutation_entropy(pattern_counts, D)\n",
        "    print(f\"Permutation Entropy (D={D}): {entropy}\")\n",
        "\n",
        "    conditional_probabilities, transition_matrix, unique_patterns = calculate_conditional_probabilities_and_matrix(valid_patterns, D)\n",
        "    for current, probs in conditional_probabilities.items():\n",
        "        print(f'Conditional probabilities for {current}:')\n",
        "        for next_pattern, prob in probs.items():\n",
        "            print(f'  P({next_pattern}|{current}) = {prob:.4f}')\n",
        "    try:\n",
        "        plot_transition_matrix_heatmap(transition_matrix, unique_patterns, D)\n",
        "    except Exception as e:  # Catch the exception and assign it to variable 'e'\n",
        "        print(f\"An error occurred: {e}\")  # Print the error message\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "weaver",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
